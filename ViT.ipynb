{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Transformer for Skin Cancer Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mh5py\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m \n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import ViTForImageClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "from transformers import ViTImageProcessor\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "import h5py\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wd/wcjpwvbx6ql2slnp2p7cvn2m0000gn/T/ipykernel_14380/4180780485.py:5: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'{BASE_PATH}/train-metadata.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>target</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>sex</th>\n",
       "      <th>anatom_site_general</th>\n",
       "      <th>clin_size_long_diam_mm</th>\n",
       "      <th>image_type</th>\n",
       "      <th>tbp_tile_type</th>\n",
       "      <th>tbp_lv_A</th>\n",
       "      <th>...</th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>iddx_full</th>\n",
       "      <th>iddx_1</th>\n",
       "      <th>iddx_2</th>\n",
       "      <th>iddx_3</th>\n",
       "      <th>iddx_4</th>\n",
       "      <th>iddx_5</th>\n",
       "      <th>mel_mitotic_index</th>\n",
       "      <th>mel_thick_mm</th>\n",
       "      <th>tbp_lv_dnn_lesion_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0015670</td>\n",
       "      <td>0</td>\n",
       "      <td>IP_1235828</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>3.04</td>\n",
       "      <td>TBP tile: close-up</td>\n",
       "      <td>3D: white</td>\n",
       "      <td>20.244422</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.517282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015845</td>\n",
       "      <td>0</td>\n",
       "      <td>IP_8170065</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>1.10</td>\n",
       "      <td>TBP tile: close-up</td>\n",
       "      <td>3D: white</td>\n",
       "      <td>31.712570</td>\n",
       "      <td>...</td>\n",
       "      <td>IL_6727506</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.141455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        isic_id  target  patient_id  age_approx   sex anatom_site_general  \\\n",
       "0  ISIC_0015670       0  IP_1235828        60.0  male     lower extremity   \n",
       "1  ISIC_0015845       0  IP_8170065        60.0  male           head/neck   \n",
       "\n",
       "   clin_size_long_diam_mm          image_type tbp_tile_type   tbp_lv_A  ...  \\\n",
       "0                    3.04  TBP tile: close-up     3D: white  20.244422  ...   \n",
       "1                    1.10  TBP tile: close-up     3D: white  31.712570  ...   \n",
       "\n",
       "    lesion_id  iddx_full  iddx_1  iddx_2  iddx_3  iddx_4  iddx_5  \\\n",
       "0         NaN     Benign  Benign     NaN     NaN     NaN     NaN   \n",
       "1  IL_6727506     Benign  Benign     NaN     NaN     NaN     NaN   \n",
       "\n",
       "   mel_mitotic_index  mel_thick_mm  tbp_lv_dnn_lesion_confidence  \n",
       "0                NaN           NaN                     97.517282  \n",
       "1                NaN           NaN                      3.141455  \n",
       "\n",
       "[2 rows x 55 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>sex</th>\n",
       "      <th>anatom_site_general</th>\n",
       "      <th>clin_size_long_diam_mm</th>\n",
       "      <th>image_type</th>\n",
       "      <th>tbp_tile_type</th>\n",
       "      <th>tbp_lv_A</th>\n",
       "      <th>tbp_lv_Aext</th>\n",
       "      <th>...</th>\n",
       "      <th>tbp_lv_radial_color_std_max</th>\n",
       "      <th>tbp_lv_stdL</th>\n",
       "      <th>tbp_lv_stdLExt</th>\n",
       "      <th>tbp_lv_symm_2axis</th>\n",
       "      <th>tbp_lv_symm_2axis_angle</th>\n",
       "      <th>tbp_lv_x</th>\n",
       "      <th>tbp_lv_y</th>\n",
       "      <th>tbp_lv_z</th>\n",
       "      <th>attribution</th>\n",
       "      <th>copyright_license</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0015657</td>\n",
       "      <td>IP_6074337</td>\n",
       "      <td>45.0</td>\n",
       "      <td>male</td>\n",
       "      <td>posterior torso</td>\n",
       "      <td>2.70</td>\n",
       "      <td>TBP tile: close-up</td>\n",
       "      <td>3D: XP</td>\n",
       "      <td>22.80433</td>\n",
       "      <td>20.007270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304827</td>\n",
       "      <td>1.281532</td>\n",
       "      <td>2.299935</td>\n",
       "      <td>0.479339</td>\n",
       "      <td>20</td>\n",
       "      <td>-155.06510</td>\n",
       "      <td>1511.222000</td>\n",
       "      <td>113.980100</td>\n",
       "      <td>Memorial Sloan Kettering Cancer Center</td>\n",
       "      <td>CC-BY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015729</td>\n",
       "      <td>IP_1664139</td>\n",
       "      <td>35.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>2.52</td>\n",
       "      <td>TBP tile: close-up</td>\n",
       "      <td>3D: XP</td>\n",
       "      <td>16.64867</td>\n",
       "      <td>9.657964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.271940</td>\n",
       "      <td>2.011223</td>\n",
       "      <td>0.426230</td>\n",
       "      <td>25</td>\n",
       "      <td>-112.36924</td>\n",
       "      <td>629.535889</td>\n",
       "      <td>-15.019287</td>\n",
       "      <td>Frazer Institute, The University of Queensland...</td>\n",
       "      <td>CC-BY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        isic_id  patient_id  age_approx     sex anatom_site_general  \\\n",
       "0  ISIC_0015657  IP_6074337        45.0    male     posterior torso   \n",
       "1  ISIC_0015729  IP_1664139        35.0  female     lower extremity   \n",
       "\n",
       "   clin_size_long_diam_mm          image_type tbp_tile_type  tbp_lv_A  \\\n",
       "0                    2.70  TBP tile: close-up        3D: XP  22.80433   \n",
       "1                    2.52  TBP tile: close-up        3D: XP  16.64867   \n",
       "\n",
       "   tbp_lv_Aext  ...  tbp_lv_radial_color_std_max  tbp_lv_stdL  tbp_lv_stdLExt  \\\n",
       "0    20.007270  ...                     0.304827     1.281532        2.299935   \n",
       "1     9.657964  ...                     0.000000     1.271940        2.011223   \n",
       "\n",
       "   tbp_lv_symm_2axis  tbp_lv_symm_2axis_angle   tbp_lv_x     tbp_lv_y  \\\n",
       "0           0.479339                       20 -155.06510  1511.222000   \n",
       "1           0.426230                       25 -112.36924   629.535889   \n",
       "\n",
       "     tbp_lv_z                                        attribution  \\\n",
       "0  113.980100             Memorial Sloan Kettering Cancer Center   \n",
       "1  -15.019287  Frazer Institute, The University of Queensland...   \n",
       "\n",
       "   copyright_license  \n",
       "0              CC-BY  \n",
       "1              CC-BY  \n",
       "\n",
       "[2 rows x 44 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#loading data\n",
    "BASE_PATH = \"isic-2024-challenge\"\n",
    "\n",
    "# Train + Valid\n",
    "df = pd.read_csv(f'{BASE_PATH}/train-metadata.csv')\n",
    "df = df.ffill()\n",
    "display(df.head(2))\n",
    "\n",
    "# Testing\n",
    "testing_df = pd.read_csv(f'{BASE_PATH}/test-metadata.csv')\n",
    "testing_df = testing_df.ffill()\n",
    "display(testing_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution Before Sampling (%):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    99.902009\n",
       "1     0.097991\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Distribution After Sampling (%):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    67.09645\n",
       "1    32.90355\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: {0: np.float64(0.7451959071624656), 1: np.float64(1.519592875318066)}\n"
     ]
    }
   ],
   "source": [
    "#Handle Class Imbalance\n",
    "print(\"Class Distribution Before Sampling (%):\")\n",
    "display(df.target.value_counts(normalize=True)*100)\n",
    "seed = 1\n",
    "neg_sample = .01\n",
    "pos_sample = 5.0\n",
    "# Sampling\n",
    "positive_df = df.query(\"target==0\").sample(frac=neg_sample, random_state=seed)\n",
    "negative_df = df.query(\"target==1\").sample(frac=pos_sample, replace=True, random_state=seed)\n",
    "df = pd.concat([positive_df, negative_df], axis=0).sample(frac=1.0)\n",
    "\n",
    "print(\"\\nClass Distribution After Sampling (%):\")\n",
    "display(df.target.value_counts(normalize=True)*100)\n",
    "\n",
    "# Assume df is your DataFrame and 'target' is the column with class labels\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(df['target']), y=df['target'])\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "print(\"Class Weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_validation_hdf5 = h5py.File(f\"{BASE_PATH}/train-image.hdf5\", 'r')\n",
    "testing_hdf5 = h5py.File(f\"{BASE_PATH}/test-image.hdf5\", 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Byte String: b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00'....\n",
      "Image:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m nparr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(byte_string, np\u001b[38;5;241m.\u001b[39muint8)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mimdecode(nparr, cv2\u001b[38;5;241m.\u001b[39mIMREAD_COLOR)[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;66;03m# reverse last axis for bgr -> rgb\u001b[39;00m\n\u001b[1;32m     12\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(image);\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "isic_id = df.isic_id.iloc[0]\n",
    "\n",
    "# Image as Byte String\n",
    "byte_string = training_validation_hdf5[isic_id][()]\n",
    "print(f\"Byte String: {byte_string[:20]}....\")\n",
    "\n",
    "# Convert byte string to numpy array\n",
    "nparr = np.frombuffer(byte_string, np.uint8)\n",
    "\n",
    "print(\"Image:\")\n",
    "image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)[...,::-1] # reverse last axis for bgr -> rgb\n",
    "plt.imshow(image);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'File' object has no attribute 'map'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m         example[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpixel_values\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m transform(example[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m example\n\u001b[0;32m---> 14\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m(preprocess_images, batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'File' object has no attribute 'map'"
     ]
    }
   ],
   "source": [
    "#load/preprosses dataset\n",
    "model_name='google/vit-base-patch16-224-in21k'\n",
    "processor = ViTImageProcessor.from_pretrained(model_name)\n",
    "transform = Compose([\n",
    "        Resize((224, 224)),\n",
    "        ToTensor(),\n",
    "        Normalize(mean=processor.image_mean, std=processor.image_std),\n",
    "    ])\n",
    "\n",
    "def preprocess_images(example):\n",
    "        example['pixel_values'] = transform(example['image'])\n",
    "        return example\n",
    "\n",
    "ds = ds.map(preprocess_images, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model from google\n",
    "model = ViTForImageClassification.from_pretrained(model_name)\n",
    "\n",
    "#Make a preprocess function  as per the tutorial\n",
    "def preprocess_images(example):\n",
    "    example['pixel_values'] = torch.tensor(example['pixel_values'])\n",
    "    return example\n",
    "\n",
    "# Make sure its the right tensor types\n",
    "def collate_fn(batch):\n",
    "    pixel_values = torch.stack([torch.tensor(example['pixel_values']) for example in batch])\n",
    "    labels = torch.tensor([example['target'] for example in batch])\n",
    "    return {'pixel_values': pixel_values, 'labels': labels}\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./vit-finetuned-beans',\n",
    "    per_device_train_batch_size=16,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=4,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds['train'],\n",
    "    eval_dataset=ds['validation'],\n",
    "    data_collator=collate_fn,\n",
    "    tokenizer=processor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train da model\n",
    "trainer.train()\n",
    "\n",
    "# Save da fine-tuned model\n",
    "trainer.save_model('./vit-finetuned-beans')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
